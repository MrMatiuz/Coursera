{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза «мешка слов». Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать «мешком ингредиентов», потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные «темы». Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули *json* и *gensim*. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "*pip install gensim*\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (cuisine) и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (3.8.3)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from gensim) (2.0.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: six>=1.5.0 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from gensim) (1.14.0)\n",
      "Requirement already satisfied: boto3 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.0)\n",
      "Requirement already satisfied: boto in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: requests in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.22.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.0 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.0->boto3->smart-open>=1.8.1->gensim) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/mateliparteliani/opt/anaconda3/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.0->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 10259, 'cuisine': 'greek', 'ingredients': ['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print(recipes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая, и целиком помещается в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['romaine lettuce', 'black olives', 'grape tomatoes', 'garlic', 'pepper', 'purple onion', 'seasoning', 'garbanzo beans', 'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть полезная переменная dictionary.token2id, позволяющая находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. \n",
    "\n",
    "\n",
    "Затем вызовите метод модели *show_topics*, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода *show_topics* указать параметр *formatted=True*, то топы ингредиентов будет удобно выводить на печать, если *formatted=False*, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 24s, sys: 725 ms, total: 1min 25s\n",
      "Wall time: 1min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "LDA_model = models.ldamodel.LdaModel(corpus, id2word=dictionary, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('chopped onion', 0.10551199),\n",
       "   ('garlic cloves', 0.083032385),\n",
       "   ('salt', 0.0642796),\n",
       "   ('fat free less sodium chicken broth', 0.05447017),\n",
       "   ('sliced green onions', 0.04764844),\n",
       "   ('cooking spray', 0.047082495),\n",
       "   ('ground red pepper', 0.04544822),\n",
       "   ('water', 0.044634435),\n",
       "   ('spinach', 0.037793647),\n",
       "   ('black pepper', 0.03087291)]),\n",
       " (1,\n",
       "  [('corn kernels', 0.101355165),\n",
       "   ('diced onions', 0.08620946),\n",
       "   ('tortillas', 0.07217828),\n",
       "   ('vegetable stock', 0.06634489),\n",
       "   ('chopped fresh chives', 0.049696263),\n",
       "   ('sliced black olives', 0.04937546),\n",
       "   ('cream cheese, soften', 0.047917385),\n",
       "   ('lard', 0.043475762),\n",
       "   ('jack cheese', 0.03448586),\n",
       "   ('canned black beans', 0.024307348)]),\n",
       " (2,\n",
       "  [('olive oil', 0.0868221),\n",
       "   ('crushed red pepper', 0.059952572),\n",
       "   ('fresh parsley', 0.055572473),\n",
       "   ('garlic cloves', 0.041880533),\n",
       "   ('grated parmesan cheese', 0.03933529),\n",
       "   ('cherry tomatoes', 0.03549442),\n",
       "   ('butter', 0.035234306),\n",
       "   ('salt', 0.03442959),\n",
       "   ('low salt chicken broth', 0.03408496),\n",
       "   ('fresh rosemary', 0.03214183)]),\n",
       " (3,\n",
       "  [('bacon', 0.07406186),\n",
       "   ('salt', 0.070034064),\n",
       "   ('red pepper flakes', 0.06113123),\n",
       "   ('onions', 0.05366978),\n",
       "   ('garlic', 0.050713535),\n",
       "   ('ground black pepper', 0.048669904),\n",
       "   ('mushrooms', 0.043888584),\n",
       "   ('chicken thighs', 0.04278068),\n",
       "   ('pasta', 0.041835524),\n",
       "   ('olive oil', 0.034012336)]),\n",
       " (4,\n",
       "  [('cooking spray', 0.090782195),\n",
       "   ('salt', 0.067129046),\n",
       "   ('powdered sugar', 0.06111337),\n",
       "   ('all-purpose flour', 0.05459232),\n",
       "   ('large egg whites', 0.052343696),\n",
       "   ('sugar', 0.05029949),\n",
       "   ('large eggs', 0.04898396),\n",
       "   ('cream cheese', 0.04469629),\n",
       "   ('yellow corn meal', 0.043894257),\n",
       "   ('butter', 0.042045962)]),\n",
       " (5,\n",
       "  [('large garlic cloves', 0.09309201),\n",
       "   ('shallots', 0.091499284),\n",
       "   ('dry white wine', 0.07541723),\n",
       "   ('olive oil', 0.055893023),\n",
       "   ('finely chopped onion', 0.045013353),\n",
       "   ('unsalted butter', 0.03300117),\n",
       "   ('salt', 0.03261315),\n",
       "   ('white wine vinegar', 0.03201555),\n",
       "   ('arborio rice', 0.03061911),\n",
       "   ('saffron threads', 0.02668763)]),\n",
       " (6,\n",
       "  [('fresh thyme', 0.07862685),\n",
       "   ('dry red wine', 0.07769648),\n",
       "   ('pork tenderloin', 0.052869525),\n",
       "   ('reduced sodium soy sauce', 0.04713877),\n",
       "   ('cilantro sprigs', 0.046603274),\n",
       "   ('beef broth', 0.04143179),\n",
       "   ('peppercorns', 0.036439005),\n",
       "   ('cremini mushrooms', 0.032307755),\n",
       "   ('rosemary', 0.023097869),\n",
       "   ('daikon', 0.022761114)]),\n",
       " (7,\n",
       "  [('soy sauce', 0.09193548),\n",
       "   ('sesame oil', 0.051528394),\n",
       "   ('scallions', 0.04365305),\n",
       "   ('green onions', 0.042516768),\n",
       "   ('rice vinegar', 0.04108331),\n",
       "   ('sugar', 0.03949917),\n",
       "   ('corn starch', 0.03662732),\n",
       "   ('garlic', 0.03538574),\n",
       "   ('vegetable oil', 0.03360042),\n",
       "   ('fresh ginger', 0.02714567)]),\n",
       " (8,\n",
       "  [('garlic powder', 0.17552567),\n",
       "   ('cayenne pepper', 0.12247122),\n",
       "   ('onion powder', 0.06585199),\n",
       "   ('ground black pepper', 0.046533592),\n",
       "   ('smoked paprika', 0.043696143),\n",
       "   ('black pepper', 0.040589653),\n",
       "   ('pinenuts', 0.040199514),\n",
       "   ('salt', 0.03784343),\n",
       "   ('fresh spinach', 0.025849327),\n",
       "   ('dried oregano', 0.02569928)]),\n",
       " (9,\n",
       "  [('extra-virgin olive oil', 0.113495275),\n",
       "   ('garlic cloves', 0.067181185),\n",
       "   ('fresh lemon juice', 0.06027693),\n",
       "   ('salt', 0.056391764),\n",
       "   ('olive oil', 0.05332559),\n",
       "   ('ground black pepper', 0.0519517),\n",
       "   ('plum tomatoes', 0.045928095),\n",
       "   ('purple onion', 0.042982813),\n",
       "   ('fresh basil', 0.03599843),\n",
       "   ('balsamic vinegar', 0.034345422)]),\n",
       " (10,\n",
       "  [('broccoli florets', 0.064963385),\n",
       "   ('button mushrooms', 0.049411967),\n",
       "   ('crème fraîche', 0.04829676),\n",
       "   ('yellow squash', 0.045992807),\n",
       "   ('radishes', 0.04451335),\n",
       "   ('greek style plain yogurt', 0.038467254),\n",
       "   ('pork sausages', 0.038284197),\n",
       "   ('watercress', 0.034920514),\n",
       "   ('quickcooking grits', 0.032640964),\n",
       "   ('ripe olives', 0.030846857)]),\n",
       " (11,\n",
       "  [('lime', 0.13302943),\n",
       "   ('lime juice', 0.11372325),\n",
       "   ('fresh cilantro', 0.05535831),\n",
       "   ('chopped cilantro', 0.03671244),\n",
       "   ('purple onion', 0.0353524),\n",
       "   ('mango', 0.030760624),\n",
       "   ('garlic', 0.03046131),\n",
       "   ('lime wedges', 0.027578557),\n",
       "   ('jalapeno chilies', 0.027450802),\n",
       "   ('thai chile', 0.021696253)]),\n",
       " (12,\n",
       "  [('cheese', 0.09621293),\n",
       "   ('ricotta cheese', 0.09278026),\n",
       "   ('orange juice', 0.08755198),\n",
       "   ('sliced mushrooms', 0.059149094),\n",
       "   ('baby spinach', 0.05818009),\n",
       "   ('vegetable broth', 0.05637783),\n",
       "   ('vegetable oil cooking spray', 0.051833898),\n",
       "   ('frozen chopped spinach', 0.03718596),\n",
       "   ('part-skim mozzarella cheese', 0.03464545),\n",
       "   ('italian sausage', 0.033475757)]),\n",
       " (13,\n",
       "  [('diced tomatoes', 0.093241364),\n",
       "   ('onions', 0.06300844),\n",
       "   ('dried oregano', 0.06198474),\n",
       "   ('tomato sauce', 0.05305232),\n",
       "   ('garlic', 0.04812112),\n",
       "   ('salt', 0.04612255),\n",
       "   ('tomato paste', 0.045916803),\n",
       "   ('olive oil', 0.038472116),\n",
       "   ('crushed tomatoes', 0.03310621),\n",
       "   ('ground beef', 0.029434621)]),\n",
       " (14,\n",
       "  [('tomatoes', 0.12056759),\n",
       "   ('salt', 0.08720797),\n",
       "   ('red wine vinegar', 0.0855628),\n",
       "   ('olive oil', 0.07166882),\n",
       "   ('cucumber', 0.06867392),\n",
       "   ('pepper', 0.0526374),\n",
       "   ('fresh oregano', 0.044323884),\n",
       "   ('lemon juice', 0.041226983),\n",
       "   ('purple onion', 0.034349166),\n",
       "   ('garlic', 0.03265157)]),\n",
       " (15,\n",
       "  [('lemon', 0.20206289),\n",
       "   ('orange', 0.055009045),\n",
       "   ('boiling water', 0.052957147),\n",
       "   ('fine sea salt', 0.049242906),\n",
       "   ('sugar', 0.045223705),\n",
       "   ('cold water', 0.043739863),\n",
       "   ('fennel seeds', 0.03384918),\n",
       "   ('almonds', 0.031643815),\n",
       "   ('water', 0.03128496),\n",
       "   ('mint', 0.027949333)]),\n",
       " (16,\n",
       "  [('chopped cilantro fresh', 0.10257552),\n",
       "   ('fresh lime juice', 0.076238036),\n",
       "   ('jalapeno chilies', 0.06870507),\n",
       "   ('white onion', 0.051150396),\n",
       "   ('salt', 0.04559182),\n",
       "   ('avocado', 0.042429563),\n",
       "   ('ground cumin', 0.037982874),\n",
       "   ('garlic cloves', 0.03718146),\n",
       "   ('vegetable oil', 0.027618224),\n",
       "   ('cilantro leaves', 0.027483657)]),\n",
       " (17,\n",
       "  [('ground ginger', 0.10009347),\n",
       "   ('ground cinnamon', 0.099753805),\n",
       "   ('raisins', 0.08146151),\n",
       "   ('ground cloves', 0.07687648),\n",
       "   ('white wine', 0.0705542),\n",
       "   ('ground allspice', 0.060998686),\n",
       "   ('fresh mushrooms', 0.054939628),\n",
       "   ('lean ground beef', 0.049981847),\n",
       "   ('dried rosemary', 0.03226185),\n",
       "   ('iceberg lettuce', 0.029935902)]),\n",
       " (18,\n",
       "  [('parmesan cheese', 0.11827853),\n",
       "   ('warm water', 0.07323131),\n",
       "   ('salt', 0.06323314),\n",
       "   ('olive oil', 0.053163927),\n",
       "   ('dried basil', 0.050129972),\n",
       "   ('grits', 0.03948412),\n",
       "   ('kale', 0.032848064),\n",
       "   ('plain flour', 0.03138309),\n",
       "   ('water', 0.027573025),\n",
       "   ('dry yeast', 0.027247302)]),\n",
       " (19,\n",
       "  [('unsalted butter', 0.12158404),\n",
       "   ('large eggs', 0.09737995),\n",
       "   ('all-purpose flour', 0.09656858),\n",
       "   ('salt', 0.075563036),\n",
       "   ('sugar', 0.061287478),\n",
       "   ('whole milk', 0.039257027),\n",
       "   ('granulated sugar', 0.037924375),\n",
       "   ('baking powder', 0.033421762),\n",
       "   ('large egg yolks', 0.02592417),\n",
       "   ('buttermilk', 0.025835525)]),\n",
       " (20,\n",
       "  [('flat leaf parsley', 0.11833439),\n",
       "   ('freshly ground pepper', 0.10147095),\n",
       "   ('extra-virgin olive oil', 0.055440795),\n",
       "   ('garlic cloves', 0.052536257),\n",
       "   ('large shrimp', 0.04439321),\n",
       "   ('olive oil', 0.042900138),\n",
       "   ('salt', 0.041966368),\n",
       "   ('dry bread crumbs', 0.03288877),\n",
       "   ('ground black pepper', 0.026481865),\n",
       "   ('kosher salt', 0.024302138)]),\n",
       " (21,\n",
       "  [('chicken broth', 0.14509839),\n",
       "   ('green bell pepper', 0.06691421),\n",
       "   ('boneless skinless chicken breast halves', 0.059025038),\n",
       "   ('onions', 0.054916807),\n",
       "   ('boneless skinless chicken breasts', 0.05465062),\n",
       "   ('chicken breasts', 0.048208743),\n",
       "   ('red bell pepper', 0.04174076),\n",
       "   ('butter', 0.04029683),\n",
       "   ('pepper', 0.03962653),\n",
       "   ('salt', 0.035539526)]),\n",
       " (22,\n",
       "  [('grated parmesan cheese', 0.114769004),\n",
       "   ('olive oil', 0.06298331),\n",
       "   ('zucchini', 0.057088017),\n",
       "   ('salt', 0.045280453),\n",
       "   ('garlic', 0.041572243),\n",
       "   ('mozzarella cheese', 0.04090784),\n",
       "   ('shredded mozzarella cheese', 0.03778829),\n",
       "   ('eggplant', 0.036699228),\n",
       "   ('pepper', 0.034934632),\n",
       "   ('eggs', 0.032524396)]),\n",
       " (23,\n",
       "  [('brown sugar', 0.07811723),\n",
       "   ('water', 0.050611958),\n",
       "   ('salt', 0.0497623),\n",
       "   ('soy sauce', 0.04814451),\n",
       "   ('white pepper', 0.046296027),\n",
       "   ('oil', 0.043943144),\n",
       "   ('sugar', 0.04044425),\n",
       "   ('sauce', 0.03850152),\n",
       "   ('ketchup', 0.034589797),\n",
       "   ('garlic', 0.03371746)]),\n",
       " (24,\n",
       "  [('ground cumin', 0.07393955),\n",
       "   ('ground coriander', 0.046768084),\n",
       "   ('salt', 0.046401065),\n",
       "   ('curry powder', 0.03885949),\n",
       "   ('onions', 0.03359749),\n",
       "   ('garlic', 0.028768836),\n",
       "   ('vegetable oil', 0.027797239),\n",
       "   ('ground turmeric', 0.026923489),\n",
       "   ('garlic cloves', 0.026650775),\n",
       "   ('fresh ginger', 0.024495278)]),\n",
       " (25,\n",
       "  [('hot water', 0.08947368),\n",
       "   ('chopped garlic', 0.08314913),\n",
       "   ('peanut oil', 0.06496147),\n",
       "   ('rice wine', 0.058695957),\n",
       "   ('hot red pepper flakes', 0.045849778),\n",
       "   ('corn oil', 0.036521085),\n",
       "   ('fontina cheese', 0.032588813),\n",
       "   ('marsala wine', 0.030509813),\n",
       "   ('seasoning', 0.03024059),\n",
       "   ('garlic chili sauce', 0.029476969)]),\n",
       " (26,\n",
       "  [('mirin', 0.08184621),\n",
       "   ('chickpeas', 0.07187458),\n",
       "   ('red pepper', 0.05160467),\n",
       "   ('mint leaves', 0.049639262),\n",
       "   ('chopped fresh mint', 0.04825417),\n",
       "   ('juice', 0.048129674),\n",
       "   ('sugar', 0.03890628),\n",
       "   ('fresh coriander', 0.036917552),\n",
       "   ('sake', 0.034948707),\n",
       "   ('grated lemon zest', 0.030167086)]),\n",
       " (27,\n",
       "  [('heavy cream', 0.18497995),\n",
       "   ('cheddar cheese', 0.10192716),\n",
       "   ('frozen peas', 0.07063504),\n",
       "   ('grated nutmeg', 0.06605831),\n",
       "   ('bananas', 0.041196134),\n",
       "   ('bread', 0.03667532),\n",
       "   ('ice', 0.025985282),\n",
       "   ('adobo sauce', 0.023908097),\n",
       "   ('old bay seasoning', 0.023094011),\n",
       "   ('butter', 0.022579717)]),\n",
       " (28,\n",
       "  [('oil', 0.11522546),\n",
       "   ('salt', 0.086835615),\n",
       "   ('cilantro leaves', 0.052779507),\n",
       "   ('green chilies', 0.051236328),\n",
       "   ('cumin seed', 0.048443887),\n",
       "   ('onions', 0.046263505),\n",
       "   ('ground turmeric', 0.042094264),\n",
       "   ('water', 0.04085159),\n",
       "   ('chili powder', 0.032499336),\n",
       "   ('tomatoes', 0.029237764)]),\n",
       " (29,\n",
       "  [('sour cream', 0.07743677),\n",
       "   ('salsa', 0.047229268),\n",
       "   ('flour tortillas', 0.0466243),\n",
       "   ('chili powder', 0.045378562),\n",
       "   ('corn tortillas', 0.041704077),\n",
       "   ('shredded cheddar cheese', 0.04120267),\n",
       "   ('black beans', 0.04003728),\n",
       "   ('cilantro', 0.035525333),\n",
       "   ('salt', 0.029534537),\n",
       "   ('ground cumin', 0.028014202)]),\n",
       " (30,\n",
       "  [('sugar', 0.09331752),\n",
       "   ('whipping cream', 0.080579184),\n",
       "   ('egg yolks', 0.07642158),\n",
       "   ('vanilla extract', 0.050681394),\n",
       "   ('butter', 0.05028985),\n",
       "   ('egg whites', 0.04915123),\n",
       "   ('half & half', 0.042951252),\n",
       "   ('sweetened condensed milk', 0.0369576),\n",
       "   ('water', 0.03463116),\n",
       "   ('strawberries', 0.031121783)]),\n",
       " (31,\n",
       "  [('shrimp', 0.102359936),\n",
       "   ('medium shrimp', 0.06292084),\n",
       "   ('long-grain rice', 0.04497901),\n",
       "   ('vegetable oil', 0.04446947),\n",
       "   ('green onions', 0.03641775),\n",
       "   ('long grain white rice', 0.03515395),\n",
       "   ('rice noodles', 0.034855902),\n",
       "   ('hot pepper sauce', 0.03463772),\n",
       "   ('scallions', 0.028577073),\n",
       "   ('asian fish sauce', 0.026012387)]),\n",
       " (32,\n",
       "  [('eggs', 0.11213419),\n",
       "   ('milk', 0.10442591),\n",
       "   ('salt', 0.09609212),\n",
       "   ('butter', 0.07255012),\n",
       "   ('all-purpose flour', 0.067550406),\n",
       "   ('flour', 0.042022534),\n",
       "   ('baking powder', 0.041263264),\n",
       "   ('sugar', 0.040136065),\n",
       "   ('white sugar', 0.04007245),\n",
       "   ('water', 0.022987748)]),\n",
       " (33,\n",
       "  [('rice', 0.06256682),\n",
       "   ('coriander', 0.05493443),\n",
       "   ('onions', 0.048950084),\n",
       "   ('salt', 0.047661252),\n",
       "   ('garam masala', 0.0412198),\n",
       "   ('tumeric', 0.040127896),\n",
       "   ('ginger', 0.04000567),\n",
       "   ('cabbage', 0.03805968),\n",
       "   ('garlic', 0.03530765),\n",
       "   ('ghee', 0.033888273)]),\n",
       " (34,\n",
       "  [('cinnamon sticks', 0.0906538),\n",
       "   ('clove', 0.084414154),\n",
       "   ('black peppercorns', 0.07068197),\n",
       "   ('chopped tomatoes', 0.041457277),\n",
       "   ('cream', 0.041272424),\n",
       "   ('garlic paste', 0.03845835),\n",
       "   ('yoghurt', 0.034638125),\n",
       "   ('coriander seeds', 0.034256842),\n",
       "   ('fresh dill', 0.03250031),\n",
       "   ('cinnamon', 0.028395623)]),\n",
       " (35,\n",
       "  [('onions', 0.066598654),\n",
       "   ('bay leaves', 0.05085973),\n",
       "   ('celery', 0.050396297),\n",
       "   ('salt', 0.048673697),\n",
       "   ('bay leaf', 0.045635764),\n",
       "   ('carrots', 0.045632828),\n",
       "   ('dried thyme', 0.04561602),\n",
       "   ('water', 0.04148726),\n",
       "   ('garlic', 0.03284827),\n",
       "   ('ground black pepper', 0.030371703)]),\n",
       " (36,\n",
       "  [('salt', 0.11690514),\n",
       "   ('pepper', 0.09566874),\n",
       "   ('paprika', 0.071594104),\n",
       "   ('onions', 0.070038356),\n",
       "   ('potatoes', 0.055268742),\n",
       "   ('butter', 0.044638406),\n",
       "   ('garlic', 0.03865895),\n",
       "   ('olive oil', 0.03704227),\n",
       "   ('worcestershire sauce', 0.025252752),\n",
       "   ('carrots', 0.02482242)]),\n",
       " (37,\n",
       "  [('sea salt', 0.1092517),\n",
       "   ('coarse salt', 0.06558779),\n",
       "   ('crushed red pepper flakes', 0.056456555),\n",
       "   ('extra-virgin olive oil', 0.049991064),\n",
       "   ('ground black pepper', 0.04486122),\n",
       "   ('celery ribs', 0.04437347),\n",
       "   ('ground pepper', 0.041204296),\n",
       "   ('kosher salt', 0.039015707),\n",
       "   ('garlic cloves', 0.034251574),\n",
       "   ('parmigiano reggiano cheese', 0.03311096)]),\n",
       " (38,\n",
       "  [('fish sauce', 0.11488433),\n",
       "   ('coconut milk', 0.054774236),\n",
       "   ('garlic', 0.041953884),\n",
       "   ('shallots', 0.03720233),\n",
       "   ('red chili peppers', 0.035959106),\n",
       "   ('lemongrass', 0.03430277),\n",
       "   ('sugar', 0.02794982),\n",
       "   ('vegetable oil', 0.025905462),\n",
       "   ('boneless chicken skinless thigh', 0.024276022),\n",
       "   ('cooking oil', 0.024132773)]),\n",
       " (39,\n",
       "  [('mayonaise', 0.15268074),\n",
       "   ('dijon mustard', 0.09496008),\n",
       "   ('cider vinegar', 0.06909293),\n",
       "   ('cracked black pepper', 0.06902178),\n",
       "   ('roma tomatoes', 0.046651166),\n",
       "   ('white rice', 0.04344822),\n",
       "   ('lemon wedge', 0.043112494),\n",
       "   ('romaine lettuce', 0.035987865),\n",
       "   ('chicken wings', 0.024282426),\n",
       "   ('green onions', 0.023626443)])]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics = LDA_model.show_topics(num_topics=40, num_words=10, formatted=False)\n",
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fresh parsley'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics[2][1][2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23, 9, 8, 1, 0, 2]\n",
      "CPU times: user 1.56 ms, sys: 124 µs, total: 1.69 ms\n",
      "Wall time: 1.33 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ingredients = [\"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"]\n",
    "res = []\n",
    "for ingredient in ingredients:\n",
    "    count = 0\n",
    "    for i in range(40):\n",
    "        for j in range(10):\n",
    "            if topics[i][1][j][0] == ingredient:\n",
    "                count += 1\n",
    "                break;\n",
    "    res.append(count)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "#     with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "#         fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))\n",
    "\n",
    "def save_answers1(res):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in res]))\n",
    "\n",
    "save_answers1(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами — фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная *dfs* — это словарь, ключами которого являются id токена, а элементами — число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря *filter_tokens*, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after — размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after — суммарное количество ингредиентов в корпусе (для каждого документа вычислите число различных ингредиентов в нем и просуммируйте по всем документам) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6702 6714\n"
     ]
    }
   ],
   "source": [
    "tokens_keys_del = []\n",
    "for key in dictionary2.dfs.keys():\n",
    "    if dictionary2.dfs[key] > 4000:\n",
    "        tokens_keys_del.append(key)\n",
    "\n",
    "dictionary2.filter_tokens(tokens_keys_del)\n",
    "\n",
    "print(len(dictionary2), len(dictionary))\n",
    "dict_size_before, dict_size_after = len(dictionary), len(dictionary2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = [dictionary2.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(corpus):\n",
    "    corpus_size = 0\n",
    "    for doc in corpus:\n",
    "        corpus_size += len(doc)\n",
    "    return corpus_size\n",
    "\n",
    "corpus_size_before, corpus_size_after = counter(corpus), counter(corpus2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictionary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом *top_topics* модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 7s, sys: 522 ms, total: 1min 8s\n",
      "Wall time: 53.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "LDA_model_2 = models.ldamodel.LdaModel(corpus2, id2word=dictionary2, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(a):\n",
    "    mean_res = 0\n",
    "    for doc in a:\n",
    "        mean_res += doc[1]\n",
    "    return mean_res / len(a)\n",
    "\n",
    "coherence = mean(LDA_model.top_topics(corpus))\n",
    "coherence2 = mean(LDA_model_2.top_topics(corpus2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.347354396943141 -8.596629015979598\n"
     ]
    }
   ],
   "source": [
    "print(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers3(-627.26151034, -682.552673193)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers3(coherence, coherence2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом *get_document_topics* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(25, 0.12812185), (31, 0.6175929), (33, 0.13865705)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model_2.get_document_topics(corpus2[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной *.alpha* второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025, 0.025,\n",
       "       0.025, 0.025, 0.025, 0.025], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model_2.alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 4. Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр alpha=1, passes=5. Не забудьте про фиксацию seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, превосходящих 0.01, в матрицах темы-документы обеих моделей. Другими словами, запросите темы модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.3 s, sys: 383 ms, total: 53.7 s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "LDA_model_3 = models.ldamodel.LdaModel(corpus2, id2word=dictionary2, num_topics=40, passes=5, alpha=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.021397727),\n",
       " (1, 0.021295454),\n",
       " (2, 0.021276837),\n",
       " (3, 0.021365965),\n",
       " (4, 0.021295374),\n",
       " (5, 0.021311197),\n",
       " (6, 0.021304982),\n",
       " (7, 0.021280425),\n",
       " (8, 0.02140145),\n",
       " (9, 0.021379592),\n",
       " (10, 0.021838177),\n",
       " (11, 0.02149255),\n",
       " (12, 0.021276837),\n",
       " (13, 0.022190176),\n",
       " (14, 0.021718247),\n",
       " (15, 0.0215067),\n",
       " (16, 0.021404259),\n",
       " (17, 0.021964798),\n",
       " (18, 0.021329323),\n",
       " (19, 0.021678502),\n",
       " (20, 0.024643334),\n",
       " (21, 0.021277266),\n",
       " (22, 0.021276837),\n",
       " (23, 0.021284845),\n",
       " (24, 0.021772005),\n",
       " (25, 0.02149466),\n",
       " (26, 0.021462575),\n",
       " (27, 0.021634243),\n",
       " (28, 0.021495286),\n",
       " (29, 0.02130316),\n",
       " (30, 0.04261504),\n",
       " (31, 0.09219822),\n",
       " (32, 0.021500481),\n",
       " (33, 0.021278715),\n",
       " (34, 0.021446725),\n",
       " (35, 0.021365961),\n",
       " (36, 0.021331862),\n",
       " (37, 0.021289436),\n",
       " (38, 0.021277951),\n",
       " (39, 0.068342835)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA_model_3.get_document_topics(corpus2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203717 1590960\n"
     ]
    }
   ],
   "source": [
    "def s(model):\n",
    "    sum_ = 0\n",
    "    for i in range(len(model)):\n",
    "        for p in model[i]:\n",
    "            sum_ += 1\n",
    "    return sum_\n",
    "\n",
    "count_model2 = s(LDA_model_2.get_document_topics(corpus2, minimum_probability=0.01))\n",
    "count_model3 = s(LDA_model_3.get_document_topics(corpus2, minimum_probability=0.01))\n",
    "print(count_model2,count_model3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers4(count_model2, count_model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр __alpha__ влияет на разреженность распределений тем в документах. Аналогично гиперпараметр __eta__ влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда, распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [r[\"cuisine\"] for r in recipes]\n",
    "X = np.zeros((len(recipes), 40))\n",
    "for i in range(len(recipes)):\n",
    "    topics = LDA_model_2.get_document_topics(corpus2[i])\n",
    "    for topic in topics:\n",
    "        idx = topic[0]\n",
    "        val = topic[1]\n",
    "        X[i,idx]=val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100)\n",
    "score = cross_val_score(model,X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55198673 0.54853307 0.55802898]\n",
      "0.5528495928782288\n"
     ]
    }
   ],
   "source": [
    "print(score)\n",
    "accuracy = np.mean(score)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_answers5(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10–15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA — вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(t, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу $A$ размера темы $x$ кухни, ее элементы $a_{tc}$ — суммы $p(t|d)$ по всем документам $d$, которые отнесены к кухне $c$. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу $A$. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
